{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Analyzing the logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run from the top of the repository\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import yaml\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "with open(\"calkit.yaml\") as f:\n",
    "    calkit_config = yaml.safe_load(f)\n",
    "\n",
    "# Load the BOOM and Kowalski configurations\n",
    "boom_params = {}\n",
    "for i in calkit_config[\"pipeline\"][\"stages\"][\"benchmark-boom\"][\"iterate_over\"]:\n",
    "    boom_params[i[\"arg_name\"]] = i[\"values\"]\n",
    "\n",
    "kowalski_params = {}\n",
    "for i in calkit_config[\"pipeline\"][\"stages\"][\"benchmark-kowalski\"][\n",
    "    \"iterate_over\"\n",
    "]:\n",
    "    kowalski_params[i[\"arg_name\"]] = i[\"values\"]\n",
    "\n",
    "# Form the matrix of parameters for each\n",
    "param_names = list(boom_params.keys())\n",
    "param_vals = list(boom_params.values())\n",
    "vals_product = list(itertools.product(*param_vals))\n",
    "for i in calkit_config[\"pipeline\"][\"stages\"][\"benchmark-boom-more\"][\n",
    "    \"iterate_over\"\n",
    "][0][\"values\"]:\n",
    "    vals_product.append(tuple(i))\n",
    "results_boom = []\n",
    "\n",
    "for vals in vals_product:\n",
    "    current_params = dict(zip(param_names, vals))\n",
    "    boom_config = (\n",
    "        f\"na={current_params['n_alert_workers']}-\"\n",
    "        f\"nml={current_params['n_ml_workers']}-\"\n",
    "        f\"nf={current_params['n_filter_workers']}\"\n",
    "    )\n",
    "    boom_consumer_log_fpath = f\"logs/boom-{boom_config}/consumer.log\"\n",
    "    boom_scheduler_log_fpath = f\"logs/boom-{boom_config}/scheduler.log\"\n",
    "    # To calculate BOOM wall time, take first timestamp from the consumer log\n",
    "    # as the start and the last timestamp of the scheduler as the end\n",
    "    if not os.path.isfile(boom_consumer_log_fpath):\n",
    "        print(f\"WARNING: {boom_consumer_log_fpath} does not exist\")\n",
    "        continue\n",
    "    with open(boom_consumer_log_fpath) as f:\n",
    "        line = f.readline()\n",
    "        t1_b = pd.to_datetime(\n",
    "            line.split()[2].replace(\"\\x1b[2m\", \"\").replace(\"\\x1b[0m\", \"\")\n",
    "        )\n",
    "    with open(boom_scheduler_log_fpath) as f:\n",
    "        lines = f.readlines()\n",
    "        line = lines[-3]\n",
    "        t2_b = pd.to_datetime(\n",
    "            line.split()[2].replace(\"\\x1b[2m\", \"\").replace(\"\\x1b[0m\", \"\")\n",
    "        )\n",
    "    current_params[\"start_time\"] = t1_b\n",
    "    current_params[\"end_time\"] = t2_b\n",
    "    boom_wall_time = t2_b - t1_b\n",
    "    results_boom.append(current_params)\n",
    "\n",
    "df_boom = pl.DataFrame(results_boom).with_columns(\n",
    "    (pl.col(\"end_time\") - pl.col(\"start_time\"))\n",
    "    .dt.total_seconds()\n",
    "    .alias(\"wall_time_s\")\n",
    ")\n",
    "\n",
    "# Kowalski only has one parameter name, so we don't need the product\n",
    "param_name = list(kowalski_params.keys())[0]\n",
    "param_vals = kowalski_params[param_name]\n",
    "results_kowalski = []\n",
    "\n",
    "for val in param_vals:\n",
    "    res = {param_name: val}\n",
    "    kowalski_config = f\"n={val}\"\n",
    "    log_fpath = f\"logs/kowalski-{kowalski_config}/supervisord.log\"\n",
    "    if not os.path.isfile(log_fpath):\n",
    "        print(f\"WARNING: {log_fpath} does not exist\")\n",
    "        continue\n",
    "    # To calculate Kowalski wall time, just use the supervisord logs\n",
    "    with open(log_fpath) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if \"alert-broker-ztf entered RUNNING state\" in line:\n",
    "                t1_k = pd.to_datetime(\"T\".join(line.split()[:2]))\n",
    "                break\n",
    "        for line in lines:\n",
    "            if \"received SIGTERM indicating exit request\" in line:\n",
    "                t2_k = pd.to_datetime(\"T\".join(line.split()[:2]))\n",
    "                break\n",
    "    # Print the total time of each, in minutes\n",
    "    kowalski_wall_time = t2_k - t1_k  # type: ignore\n",
    "    res[\"start_time\"] = t1_k\n",
    "    res[\"end_time\"] = t2_k\n",
    "    results_kowalski.append(res)\n",
    "\n",
    "df_kowalski = pl.DataFrame(results_kowalski).with_columns(\n",
    "    (pl.col(\"end_time\") - pl.col(\"start_time\"))\n",
    "    .dt.total_seconds()\n",
    "    .alias(\"wall_time_s\")\n",
    ")\n",
    "\n",
    "# Write results to file for later analysis\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "df_boom.write_csv(\"results/boom.csv\")\n",
    "df_kowalski.write_csv(\"results/kowalski.csv\")\n",
    "\n",
    "# Calculate throughput factor from a specific config for each\n",
    "boom_wall_time = (\n",
    "    df_boom.filter(\n",
    "        (pl.col(\"n_alert_workers\") == 3)\n",
    "        & (pl.col(\"n_ml_workers\") == 3)\n",
    "        & (pl.col(\"n_filter_workers\") == 1)\n",
    "    )\n",
    "    .select(\"wall_time_s\")\n",
    "    .row(0)[0]\n",
    ")\n",
    "kowalski_wall_time = (\n",
    "    df_kowalski.filter(pl.col(\"n_workers\") == 7)\n",
    "    .select(pl.col(\"wall_time_s\"))\n",
    "    .row(0)[0]\n",
    ")\n",
    "\n",
    "boom_throughput_factor = kowalski_wall_time / boom_wall_time\n",
    "print(f\"BOOM throughput factor: {boom_throughput_factor:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_tbl_rows(50)\n",
    "df_boom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kowalski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Put actual results here\n",
    "kafka_ingest_strate_mbps = \"XXXXX\"\n",
    "kafka_ingest_factor = \"XXXXX\"\n",
    "\n",
    "template = r\"\"\"% This file was automatically generated; edits will be overwritten!\n",
    "\\newcommand{\\boomthroughputfactor}{BOOM_THROUGHPUT_FACTOR}\n",
    "\\newcommand{\\kakfaingestratembps}{KAFKA_INGEST_STRATE_MBPS}\n",
    "\\newcommand{\\kakfaingestfactor}{KAFKA_INGEST_FACTOR}\n",
    "\"\"\"\n",
    "\n",
    "# This might be better with an f-string, but this is TeX and who wants to deal\n",
    "# with escaping all the braces?\n",
    "template = (\n",
    "    template.replace(\n",
    "        \"BOOM_THROUGHPUT_FACTOR\", f\"{round(boom_throughput_factor):1d}\"\n",
    "    )\n",
    "    .replace(\"KAFKA_INGEST_STRATE_MBPS\", kafka_ingest_strate_mbps)\n",
    "    .replace(\"KAFKA_INGEST_FACTOR\", kafka_ingest_factor)\n",
    ")\n",
    "\n",
    "with open(\"paper/results.tex\", \"w\") as f:\n",
    "    f.write(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Kowalski scaling\n",
    "import os\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "normalized_throughput = (\n",
    "    df_kowalski[\"wall_time_s\"].max() / df_kowalski[\"wall_time_s\"]\n",
    ")\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_kowalski[\"n_workers\"],\n",
    "        y=normalized_throughput,\n",
    "        mode=\"markers+lines\",\n",
    "        marker=dict(size=10),\n",
    "        name=\"Kowalski\",\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Number of workers\",\n",
    "    yaxis_title=\"Normalized throughput\",\n",
    "    title=None,\n",
    ")\n",
    "# Shrink top margin\n",
    "fig.update_layout(margin=dict(t=65))\n",
    "\n",
    "# Now add BOOM\n",
    "# For a given worker sum, select the highest normalized throughput, i.e.,\n",
    "# group by n_workers and select the max throughput\n",
    "df_boom = df_boom.with_columns(\n",
    "    n_workers=(\n",
    "        pl.col(\"n_alert_workers\")\n",
    "        + pl.col(\"n_ml_workers\")\n",
    "        + pl.col(\"n_filter_workers\")\n",
    "    ),\n",
    "    normalized_throughput=(\n",
    "        pl.col(\"wall_time_s\").max() / pl.col(\"wall_time_s\")\n",
    "    ),\n",
    ")\n",
    "df_boom_max = (\n",
    "    df_boom.group_by(\"n_workers\")\n",
    "    .agg(max_throughput=pl.col(\"normalized_throughput\").max())\n",
    "    .sort(\"n_workers\")\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_boom_max[\"n_workers\"],\n",
    "        y=df_boom_max[\"max_throughput\"],\n",
    "        mode=\"markers+lines\",\n",
    "        marker=dict(size=10),\n",
    "        name=\"BOOM\",\n",
    "        marker_symbol=\"triangle-up\",\n",
    "        marker_color=\"orange\",\n",
    "    )\n",
    ")\n",
    "\n",
    "os.makedirs(\"paper/figures\", exist_ok=True)\n",
    "fig.write_image(\"paper/figures/scaling.png\", width=450, height=350)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
